{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval-Augmented Generation, RAG 檢索增強生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/RAG.jpg\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 環境準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. git clone https://github.com/sevenbai/20240720_GDG_Tainan_BwAI\n",
    "2. 把 .env.sample 改名為 .env\n",
    "3. 到 https://platform.openai.com/api-keys 申請 OpenAI API Key\n",
    "4. 將 API key 填入 .env 檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# 黃仁勳 維基百科\n",
    "url = 'https://zh.wikipedia.org/zh-tw/%E9%BB%83%E4%BB%81%E5%8B%B3'\n",
    "loader = WebBaseLoader(url)\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切割 Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "for doc in document:\n",
    "    doc.page_content = re.sub(r'[\\n\\t\\s]+', ' ', doc.page_content)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
    "document_chunks = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(document_chunks))\n",
    "document_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 產生 embeddings 並建立 RetrievalQA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(document_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", max_tokens=512)\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "print(f'Chat with {url}')\n",
    "orig_ans_msgs = []\n",
    "while True:\n",
    "    query_statement = input('Enter your question: ')\n",
    "    if query_statement == '':\n",
    "        break\n",
    "    print('Q: ' + query_statement)\n",
    "    # 原始 LLM 的回答\n",
    "    orig_ans_msgs.append(HumanMessage(query_statement))\n",
    "    orig_ans_msg = llm.invoke(orig_ans_msgs)\n",
    "    print('Original answer from LLM: ' + orig_ans_msg.content, flush=True)\n",
    "    orig_ans_msgs.append(orig_ans_msg)\n",
    "    # RAG 的回答\n",
    "    ans = qa.invoke({\"query\": query_statement})\n",
    "    print(*docsearch.as_retriever().invoke(query_statement), sep='\\n', flush=True)\n",
    "    print('A: ' + ans['result'], flush=True)\n",
    "# 黃仁勳在哪裡出生？\n",
    "# 他的妻子是誰？\n",
    "# 他創辦了什麼公司？\n",
    "# NVIDIA是全球市值第幾大？\n",
    "# 總結黃仁勳的職涯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG 的發展"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adaptive RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/adaptive_RAG.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multimodal RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multimodal_RAG.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Knowledge Graph RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/knowledge_graph.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 白勝文 Seven [sevenbai@gmail.com](mailto://sevenbai@gmail.com)\n",
    "<img src=\"images/fb_qrcode.png\" width=\"200\">　　　　　　　　　\n",
    "<img src=\"images/linkedin_qrcode.png\" width=\"200\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
